--- 
title: "Tutorial of RNA-seq tumor immunity analysis"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: bookdown::gitbook
#documentclass: book
#bibliography: [book.bib, packages.bib]
#biblio-style: apalike
link-citations: yes
description: "This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook."
---

#  Introduction {#intro}

This is a tutorial about integrative computing analysis of **tumor immunity** using bulk RNA-seq data. We will focus on inferring immune infiltration, immune repertoire, immune response and neoantigen prediction from a gene expression profile.\
We developed a RNA-seq immune analysis pipeline named **RIMA** that is available at https://github.com/liulab-dfci/RIMA/.

Tumor RNA-seq has become an important technique for molecular profiling and
immune characterization of tumors. RNA-seq Immune Analysis performs
integrative computational modeling of tumor microenvironment from bulk tumor
RNA-seq data, which has the potential to offer essential insights to cancer
immunology and immune-oncology studies.\

```{r fig.align='center', echo=FALSE, fig.cap='Flowchat of RIMA pipeline'}
knitr::include_graphics('images/RIMA.png', dpi = NA)
```

 The pre-processing module includes four main procedures:\
 <ul>
 <li>**Read mapping**</li>
 <li>**Quality control**</li>
 <li>**Gene quantification**</li>
 <li>**Batch effect removal**</li>
 </ul>
 The downstream analysis includes seven modules:
 <ul>
 <li>**Differential expression analysis**</li>
 <li>**Immune infiltration estimation**</li>
 <li>**Immune repertoire inference**</li>
 <li>**Neoantigen detection**</li>
 <li>**Microbiome characterization**</li>
 <li>**Immunotherapy response prediction**</li>
 <li>**Gene fusion**</li>
 <li>**Microbiome**</li>
 </ul>
 
**Available Tools Checklist** 


| **Methods** | **Description** | 
| :---: | :---: | :---: |
|  | **---ENVIRONMENT---**| |
| rnaseq | basic tools wihout dependency |  
| rseqc | dependent packages for quality control | 
| stat_perl_r | dependent packages for plotting | 
| fusion | dependent package for fusion | 
| centrifuge | dependent package for microbiome | 
|  | **---PREPROCESSING---**| 
| STAR | Spliced Transcripts Alignment to a Reference | 
| Salmon | Gene Quantification | 
| RSeQC | High Throughput Sequence Data Evaluation | 
| batch_removal| Remove Batch Effects Using Limma | 
|  | **---DIFFERENTIAL EXPRESSION---** |  
| DESeq2 | Gene Differential Expression Analysis | 
| GSEA | Gene Set Enrichment Analysis | 
| ssGSEA | Single-sample GSEA | 
|  | **---IMMNUE REPERTOIRE---** |  
| TRUST4 | TCR and BCR Sequences Analysis | 
|  | **---IMMNUE INFILTRATION---** |  
| ImmuneDeconv | Cell Components Estimation | 
|  | **---IMMNUE RESPONSE---** |  
| MSIsensor2 | Microsatellite Instability (MSI) Detection | 
| TIDEpy | T cell dysfunction and exclusion prediction | 
|  | **---MICROBIOME---** |  
| Centrifuge | Bacterial Abundance Detection |
|  | **---Mutation---** |  
| STAR-Fusion | Identify the fusion gene pairs | 
|  | **---NEO-ANTIGEN---** |  |
| arcasHLA | HLA Class I and Class II Genes Typing | 



# How to run RIMA

## Install RIMA and Set Up the Running Environment ##

To run RIMA, you will create a working directory. In the working directory, you will install the pipeline code and other required software.

**Software requirements**

Processing power:  We usually run RIMA on a machine with 64 cores.

Memory --   You will need to reserve enough memory for the following:

  - Reference files and pipeline code -- 65 GB
  - Raw data -- we recommend reserving five times the size of your data files.  For example, if your fastq files are 50GB each, then you should allot 250GB for each fastq file. Zipped fastq files are recommended. 
  - Required software -- reserve ~20GB for installation of miniconda, mamba and snakemake.  

**Prepare a working directory**

```
mkdir RIMA
```

**Get the pipeline code**

Download the RIMA_pipeline folder to your working directory. 

```
git clone  https://github.com/kateyliu/RIMA_pipeline.git
```

**Install conda**

If conda was installed on your system (HCP or cloud instance) previously, you can skip this step. Otherwise, download and configure your conda environment. Follow the prompts on the installer screens. If you are unsure about any setting, accept the defaults.
#Note: if you install conda in the /home directory on AWS, make sure that you have enough space on root disk (>= 20G)

```
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash sh Miniconda3-latest-Linux-x86_64.sh
conda list  #to see whether you have successfully installed conda
```

**Set up the running environment**

The RIMA environment can be set up by running a shell command.  In the command, you need to specify the platform you are using -- Amazon Web Services (AWS) or Google Cloud Platform (GCP).  This process may take ten to fifteen minutes.  The user will need to answer two questions during the process -- one at the beginning of the program and one near the end.

```
#shell command for 
bash ./RIMA_environment.sh -p {platform --AWS, GCP}

#example for AWS
bash ./RIMA_environment.sh -p AWS
```

**Activate the RIMA environment**

Based on the conda environments information, the main environment "RIMA" can be activated as below.

```
export CONDA_ROOT=/home/{username}/miniconda3
export PATH=/home/{username}/miniconda3/bin:$PATH
source activate RIMA
```

## Download pre-built references 

A pre-prepared RIMA reference folder can be downloaded using the code below. 

If you want to prepare a customized reference, you can follow [this tutorial](https://crazyhottommy.github.io/computation_wiki/RIMA/build-RIMA-reference/) to build your own reference.

Currently, RIMA supports **hg38**.
 
```
cd RIMA
wget http://cistrome.org/~lyang/ref.tar.gz  

# unzip the reference  
tar -zxvf ref.tar.gz

# remove the reference zip file to save some space
rm ref.tar.gz 
```


**Optional step** \

If you download your RIMA reference folder into a directory other than RIMA, you have to change the symbolic link for the ref_files under the rnaseq_pipeline folder:
For example: if you downloaded the RIMA reference folder into /mnt/tutorial/ref_files, use the ln command to change the symbolic link

```
cd RIMA

# remove the current link of ref_files
rm ref_files

# create a new symoblic link to your reference folder
ln -s /mnt/tutorial/ref_files
```

## Prepare input files 

**Metasheet.csv**

Metasheet.csv is a comma-delimited file that resides in the RIMA_pipeline folder.  Ensure your metasheet contains **Three Required Columns** (SampleName, PatName, Group) in comma-delimited format. Enter "U"(unknown) for missing data.
You can add columns to the metasheet in order to compare other phenotypes e.g. columns for Responder, Age, Sex etc.
The Group column controls what samples will be used to run DESeq2, 'NA' indicates samples that should not be included in the comparison.

```
SampleName,PatName,Batch,Group,Age,Tissue,Replicate,Gender,Timing,Responder,TumorLocation,OngoingTreatment,PFS,Survival,OS,SampleId,syn_batch
SRR8281218,P20,1,NR,63,Brain,NA,male,Pre,NR,temporal,no,110,1,278,4790-NL-AS,1
SRR8281219,P20,1,NA,63,Brain,NA,male,Post,NR,temporal,no,110,1,278,4975-NL-AS,1
SRR8281226,P53,1,NR,70,Brain,NA,male,Pre,NR,frontal,Yes,83,1,337,3981-NL-AS,2
SRR8281236,P53,1,NA,70,Brain,2,male,Post,NR,frontal,Yes,83,1,337,4760-D1,2
SRR8281233,P56,1,NR,54,Brain,NA,female,Pre,NR,Parietal,no,83,1,83,4341-D3,3
SRR8281230,P56,1,NA,54,Brain,NA,female,Post,NR,Parietal,no,83,1,83,4680-A1,3
SRR8281244,P100,1,NA,31,Brain,NA,male,Post,R,Frontal-crossesmidline,yes,151,0,615,4956-NL-AS,2
SRR8281245,P100,1,R,31,Brain,NA,male,Pre,R,Frontal-crossesmidline,yes,151,0,615,4595-G1,2
SRR8281243,P101,1,R,32,Brain,NA,male,Pre,R,frontal,no,0,1,414,3542-NL-AS,2
SRR8281238,P102,1,NA,64,Brain,NA,female,Post,R,Temporal-anterior,yes,519,0,539,5094-NL-AS,1
SRR8281251,P101,1,NA,32,Brain,2,male,Post,R,frontal,no,0,1,414,4943-A1,2
SRR8281250,P102,1,R,64,Brain,NA,female,Pre,R,Temporal-anterior,yes,519,0,539,4443-NL-AS,1
```

**Config.yaml**

In the RIMA_pipeline folder, we have prepared a config.yaml as a template to run the pipeline. The config file is divided into three sections: (i)Fixed and user-defined parameters (ii) Cohort analysis parameters and (iii)Samples list. 

You should provide these parameters with column names that match the columns in metasheet.csv.

Below is an example of a config.yaml file. You can set the patient name as the sample name. Note: Please make sure that sample names match the metasheet. Currently, only fastq files are accepted as input (including fastq.gz).

```
---
metasheet: metasheet.csv
ref: ref.yaml
assembly: hg38
cancer_type: GBM  #TCGA cancer type abbreviations
rseqc_ref: house_keeping  #option: 'house_keeping' or 'false'. By default, a subset of housekeeping genes is used by rseqc to assess alignment quality.  This reduces the amount of time needed to run rseqc.  
mate: [1,2]               #paired-end fastq format

#########Parameter used for cohort level analysis################
design: Group #condition on which to do comparsion (as set up in metasheet.csv)
Treatment: R
Control: NR
batch: syb_batch          #option: false or a column name from the metasheet.csv.  If set to a column name in the metasheet.csv, the column name will be used for batch effect analysis (limma).  It will also be used as a covariate for differential analysis (DeSeq2) to account for batch effect.  

pre_treated: false          #option: true or false. If set to false, patients are treatment naive.  If set to true, patients have received some form of therapy prior to the current study.

#########Location of raw fastq data##############
samples:
  SRR8281218:
    - /mnt/zhao_trial/data/SRR8281218_1.fastq.gz
    - /mnt/zhao_trial/data/SRR8281218_2.fastq.gz
  SRR8281219:
    - /mnt/zhao_trial/data/SRR8281219_1.fastq.gz
    - /mnt/zhao_trial/data/SRR8281219_2.fastq.gz
  SRR8281226:
    - /mnt/zhao_trial/data/SRR8281226_1.fastq.gz
    - /mnt/zhao_trial/data/SRR8281226_2.fastq.gz
  SRR8281236:
    - /mnt/zhao_trial/data/SRR8281236_1.fastq.gz
    - /mnt/zhao_trial/data/SRR8281236_2.fastq.gz
  SRR8281230:
    - /mnt/zhao_trial/data/SRR8281230_1.fastq.gz
    - /mnt/zhao_trial/data/SRR8281230_2.fastq.gz
  SRR8281233:
    - /mnt/zhao_trial/data/SRR8281233_1.fastq.gz
    - /mnt/zhao_trial/data/SRR8281233_2.fastq.gz
  SRR8281244:
    - /mnt/zhao_trial/data/SRR8281244_1.fastq.gz
    - /mnt/zhao_trial/data/SRR8281244_2.fastq.gz
  SRR8281245:
    - /mnt/zhao_trial/data/SRR8281245_1.fastq.gz
    - /mnt/zhao_trial/data/SRR8281245_2.fastq.gz
  SRR8281243:
    - /mnt/zhao_trial/data/SRR8281243_1.fastq.gz
    - /mnt/zhao_trial/data/SRR8281243_2.fastq.gz
  SRR8281251:
    - /mnt/zhao_trial/data/SRR8281251_1.fastq.gz
    - /mnt/zhao_trial/data/SRR8281251_2.fastq.gz
  SRR8281238:
    - /mnt/zhao_trial/data/SRR8281238_1.fastq.gz
    - /mnt/zhao_trial/data/SRR8281238_2.fastq.gz
  SRR8281250:
    - /mnt/zhao_trial/data/SRR8281250_1.fastq.gz
    - /mnt/zhao_trial/data/SRR8281250_2.fastq.gz
    

```

**execution.yaml**

Use **execution.yaml** to control which modules to run in RIMA.
There are three required modules: (1) Environment (2) Preprocess individual (3) Preprocess mutation_cohort
Preprocess module outputs are required for optional modules(downstream analysis).

```
#Note: This module creates the environment necessary to run the remaining modules. Environment installation is only required for the first time on any server. For recurring users, the command can be set to false to avoid reinstallations.
environment: true  

#Note: Preprocess individual and cohort module necessary to get the alignment and quality results. Run the remaining modules only after these two modules.
preprocess_individual: true
preprocess_cohort: true

#Optional modules
#Note: The below modules are specialized modules, each dealing with specific targets. Make sure to r
un individual and cohort of each module to get all the results.

differential_expression_cohort: false

immune_infiltration_cohort: false

mutation_individual: false
mutation_cohort: false

immune_response_individual: false
immune_response_cohort: false

immune_repertoire_individual: false
immune_repertoire_cohort: false

microbiome_individual: false
microbiome_cohort: false

neoantigen_individual: false
neoantigen_cohort: false

#Note: This module generates a standalone  HTML report. It shows the results from the modules that user decides to run.
report: false

```

**ref.yaml**
The ref.yaml file provides the paths for all reference files.  If you downloaded the pre-built reference files, you should not need to change this file.

```
hg38:
###annotation path
  fasta_path: ./ref_files/GRCh38.d1.vd1.fa 
  gtf_path: ./ref_files/gencode.v22.annotation.gtf
  bed_path: ./ref_files/refseqGenes.bed
  driver_bed_path: ./ref_files/driverGene_refseqGenes.bed
  housekeeping_bed_path: ./ref_files/housekeeping_refseqGenes.bed
  trust4_reper_path: ./ref_files/TRUST4/hg38_bcrtcr.fa
  trust4_IMGT_path: ./ref_files/TRUST4/human_IMGT+C.fa
  gmt_path: ./static/ssgsea/c2.cp.kegg.v6.1.symbols.gmt

###index path
  star_index: ./ref_files/star_gdc_index/hg38/v22
  star_fusion_index: ./ref_files/fusion_gdc_index/GRCh38_v22_CTAT_lib_GDC_Mar162019/ctat_genome_lib_build_dir
  salmon_index:  ./ref_files/salmon_index/gencode.v22.ts.fa
  msisensor_index: ./ref_files/msisensor_gdc_index/hg38/microsatellite.list
  centrifuge_index: ./ref_files/centrifuge_index/p_compressed+h+v
  neoantigen_iedb_mhcI: ./ref_files/

###tool path
  msisensor2_path: ./ref_files/msisensor2
  trust4_path: ./ref_files/TRUST4
  arcasHLA_path: ./ref_files/arcasHLA
  prada_path: ./ref_files/pyPRADA/pyPRADA_1.2
```
## Execute RIMA

**Check the path of your conda env**

```
conda env list 
# conda environments:
#
base                  *  /home/ubuntu/miniconda3
centrifuge_env           /home/ubuntu/miniconda3/envs/centrifuge_env
fusion_env               /home/ubuntu/miniconda3/envs/fusion_env
rnaseq                   /home/ubuntu/miniconda3/envs/rnaseq
rseqc_env                /home/ubuntu/miniconda3/envs/rseqc_env
stat_perl_r              /home/ubuntu/miniconda3/envs/stat_perl_r
```

**Check the pipeline with a dry run to ensure correct script and data usage.**

```
snakemake -s RIMA.snakefile -np 
```

**Submit the job.**

Alignment and some of the other modules of RIMA will take several hours to run.  It is recommended that you run the RIMA in the background using a command such as nohup as below.

```
nohup time snakemake -s RIMA.snakefile -j 4 > RIMA.out &
```

note: Argument -j sets the cores for parallel runs. (e.g. '-j 4' can run 4 jobs in parallel at the same time.)  note: Here, output log records the run information.  A user may run one module at a time to obtain a record of each module's output log.

## Output
Output folders are generated in a folder called "analysis".



```{r, include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```


